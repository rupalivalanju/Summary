{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type bytes is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[42], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m     17\u001b[0m     audio_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/rupalivalanju/Documents/Practice/poc1/demo.mp3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     text_output \u001b[39m=\u001b[39m convert_audio_to_text(audio_path)\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConverted Text:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m, in \u001b[0;36mconvert_audio_to_text\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     audio_data \u001b[39m=\u001b[39m audio_file\u001b[39m.\u001b[39mread()\n\u001b[1;32m      6\u001b[0m \u001b[39m# Call the OpenAI API with the Whisper ASR system\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      8\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwhisper-1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     audio\u001b[39m=\u001b[39;49maudio_data,\n\u001b[1;32m     10\u001b[0m     content_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# Adjust content type if your audio format is different\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:581\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest_raw\u001b[39m(\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    571\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m--> 581\u001b[0m     abs_url, headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_request_raw(\n\u001b[1;32m    582\u001b[0m         url, supplied_headers, method, params, files, request_id\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    585\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(_thread_context, \u001b[39m\"\u001b[39m\u001b[39msession\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    586\u001b[0m         _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:553\u001b[0m, in \u001b[0;36mAPIRequestor._prepare_request_raw\u001b[0;34m(self, url, supplied_headers, method, params, files, request_id)\u001b[0m\n\u001b[1;32m    551\u001b[0m         data \u001b[39m=\u001b[39m params\n\u001b[1;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m params \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m files:\n\u001b[0;32m--> 553\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mdumps(params)\u001b[39m.\u001b[39mencode()\n\u001b[1;32m    554\u001b[0m         headers[\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    555\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type bytes is not JSON serializable"
     ]
    }
   ],
   "source": [
    "def convert_audio_to_text(audio_path):\n",
    "    # Read the audio file as binary data\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    # Call the OpenAI API with the Whisper ASR system\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"whisper-1\",\n",
    "        audio=audio_data,\n",
    "        content_type=\"mp3\",  # Adjust content type if your audio format is different\n",
    "        format=\"text\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def main():\n",
    "    audio_path = \"/Users/rupalivalanju/Documents/Practice/poc1/demo.mp3\"\n",
    "    text_output = convert_audio_to_text(audio_path)\n",
    "    print(\"Converted Text:\")\n",
    "    print(text_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type bytes is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[43], line 23\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m     22\u001b[0m     audio_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/rupalivalanju/Documents/Practice/poc1/WhatsApp-Audio-2023-08-08-at-06.56.03.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m     text_output \u001b[39m=\u001b[39m convert_audio_to_text(audio_path)\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConverted Text:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m, in \u001b[0;36mconvert_audio_to_text\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m     audio_data \u001b[39m=\u001b[39m audio_file\u001b[39m.\u001b[39mread()\n\u001b[1;32m     11\u001b[0m \u001b[39m# Call the OpenAI API with the Whisper ASR system\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     13\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwhisper-1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     audio\u001b[39m=\u001b[39;49maudio_data,\n\u001b[1;32m     15\u001b[0m     content_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# Adjust content type if your audio format is different\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:581\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest_raw\u001b[39m(\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    571\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m requests\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m--> 581\u001b[0m     abs_url, headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_request_raw(\n\u001b[1;32m    582\u001b[0m         url, supplied_headers, method, params, files, request_id\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    585\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(_thread_context, \u001b[39m\"\u001b[39m\u001b[39msession\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    586\u001b[0m         _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:553\u001b[0m, in \u001b[0;36mAPIRequestor._prepare_request_raw\u001b[0;34m(self, url, supplied_headers, method, params, files, request_id)\u001b[0m\n\u001b[1;32m    551\u001b[0m         data \u001b[39m=\u001b[39m params\n\u001b[1;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m params \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m files:\n\u001b[0;32m--> 553\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mdumps(params)\u001b[39m.\u001b[39mencode()\n\u001b[1;32m    554\u001b[0m         headers[\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    555\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type bytes is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = \"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\"\n",
    "\n",
    "def convert_audio_to_text(audio_path):\n",
    "    # Read the audio file as binary data\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    # Call the OpenAI API with the Whisper ASR system\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"whisper-1\",\n",
    "        audio=audio_data,\n",
    "        content_type=\"mp3\",  # Adjust content type if your audio format is different\n",
    "        format=\"text\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def main():\n",
    "    audio_path = \"/Users/rupalivalanju/Documents/Practice/poc1/WhatsApp-Audio-2023-08-08-at-06.56.03.wav\"\n",
    "    text_output = convert_audio_to_text(audio_path)\n",
    "    print(\"Converted Text:\")\n",
    "    print(text_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Invalid URL (POST /v1/engines/whisper-1/completions)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m     26\u001b[0m     audio_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/rupalivalanju/Documents/Practice/poc1/demo.mp3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m     text_output \u001b[39m=\u001b[39m convert_audio_to_text(audio_path)\n\u001b[1;32m     28\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConverted Text:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mconvert_audio_to_text\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m audio_base64 \u001b[39m=\u001b[39m base64\u001b[39m.\u001b[39mb64encode(audio_data)\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Call the OpenAI API with the Whisper ASR system\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     17\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwhisper-1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m     audio\u001b[39m=\u001b[39;49maudio_base64,\n\u001b[1;32m     19\u001b[0m     content_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmp3;base64\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Invalid URL (POST /v1/engines/whisper-1/completions)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = \"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\"\n",
    "\n",
    "def convert_audio_to_text(audio_path):\n",
    "    # Read the audio file as binary data\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    # Convert audio data to Base64\n",
    "    audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "\n",
    "    # Call the OpenAI API with the Whisper ASR system\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"whisper-1\",\n",
    "        audio=audio_base64,\n",
    "        content_type=\"mp3;base64\",\n",
    "        format=\"text\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def main():\n",
    "    audio_path = \"/Users/rupalivalanju/Documents/Practice/poc1/demo.mp3\"\n",
    "    text_output = convert_audio_to_text(audio_path)\n",
    "    print(\"Converted Text:\")\n",
    "    print(text_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (0.27.8)\n",
      "Requirement already satisfied: aiohttp in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/rupalivalanju/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (4.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import base64\n",
    "# OPENAI_API_KEY = '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'\n",
    "\n",
    "# Set your OpenAI API key using an environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"No API key provided.\")\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_text(audio_path):\n",
    "    # Read the audio file as binary data\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    encoded_audio_data = base64.b64encode(audio_data).decode(\"utf-8\")    \n",
    "\n",
    "    # Call the OpenAI API with the Whisper ASR system\n",
    "    response = openai.Completion.create(\n",
    "    engine=\"whisper-1\",  # Use the appropriate GPT model\n",
    "    audio=encoded_audio_data,\n",
    "    content_type=\"mp3\",  # Adjust content type if your audio format is different\n",
    "    format=\"text\"\n",
    ")\n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Invalid URL (POST /v1/engines/whisper-1/completions)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m(request\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     audio_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/rupalivalanju/Documents/Practice/poc1/demo.mp3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     text_output \u001b[39m=\u001b[39m convert_audio_to_text(audio_path)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConverted Text:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(text_output)\n",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m, in \u001b[0;36mconvert_audio_to_text\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     encoded_audio_data \u001b[39m=\u001b[39m base64\u001b[39m.\u001b[39mb64encode(audio_data)\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)    \n\u001b[1;32m      8\u001b[0m     \u001b[39m# Call the OpenAI API with the Whisper ASR system\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     10\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwhisper-1\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# Use the appropriate GPT model\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m     audio\u001b[39m=\u001b[39;49mencoded_audio_data,\n\u001b[1;32m     12\u001b[0m     content_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# Adjust content type if your audio format is different\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Invalid URL (POST /v1/engines/whisper-1/completions)"
     ]
    }
   ],
   "source": [
    "def main(request=\"POST\"):\n",
    "    audio_path = \"/Users/rupalivalanju/Documents/Practice/poc1/demo.mp3\"\n",
    "    text_output = convert_audio_to_text(audio_path)\n",
    "    print(\"Converted Text:\")\n",
    "    print(text_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response:\n",
      "{'error': {'message': 'The model `whisper` does not exist', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set your API key\n",
    "api_key = \"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\"\n",
    "\n",
    "# URL for the Whisper ASR API endpoint\n",
    "url = \"https://api.openai.com/v1/engines/whisper/transcribe\"\n",
    "\n",
    "# Read the audio file as binary data\n",
    "with open(\"trial.wav\", \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"audio/wav\"\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.post(url, data=audio_data, headers=headers)\n",
    "\n",
    "print(\"API Response:\")\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"financial and the economical indicators. Scope of the project was traditionally it is very difficult to predict or estimate the company going bankrupt or not. It requires high level experience in the finance domain which is costly and time consuming. So, our problem statement was building a model which will predict bankruptcy effective, effectively and accurately to decrease the time complexity and will increase the accuracy in the prediction to maximize profit and minimize risk. So, this was all about our problem statement. The next step was the understand data gathering. We get the data from the client server. Number of tables were there, there are huge number of tables were there. So, we create the engine with the help of SQL alchemy library and import the file in the Jupyter notebook. We wrote the master query and got the data in one table. So, after that the data understanding was the next step. So, we check for the rows and columns, null values and the missing values and type of data present in the data frame. So, there are huge data containing 200 columns and 1.5 million rows of rows. There was null values 50 percent more, we drop those columns. Mostly there was demographics. We filled the null values with the mean and median for continuous column and mode in the case of categorical column. And the type of data present is mostly continuous and the target column was classification type. So, it was the binary classification type problem. And the type of company was the nominal category in that particular data frame. So, that is all about understanding the data. Now, next step was exploratory data analysis. We analyze the data with the help of seaborn and matplotlib libraries. We did mostly univariate, bivariate and multivariate analysis. We check the count plot for target column. Data was imbalanced, it was 80-20. So, we did smooth sampling for balancing the data with the help of IMB learn library. Value present in the data was huge. So, feature scaling was required. We checked data and it was normally distributed. We did the standardization. And we convert the whole data into the numerical format with the help of label encoding and one-hot encoding for the nominal type of column. We used panda library for exploring data, filling null values and many more applications. So, this was all about the experimental data analysis and feature engineering. We checked for the outliers and with the help of outliers detection method such as z-score, IQR method, boxplot and scatterplot. We detect outliers and then replace those outliers with the help of imputation methods and transformation techniques. We used type I libraries for detecting outliers such as boxcost method. Then, the next and most important step was feature engineering. And it was a challenging step for me where we need to decide which features is most important and which feature is less important to drop that features from data. We were having 200 features initially. We checked null values and missing values and columns and including demographic. So, we eliminate those features and also feature containing more than 30% outlier in it. We dropped it. Obviously, after having discussion with the domain expert, we took that decision. Then after doing so, we get 70 features in our data frame on which we apply different feature selection methods such as filter, wrapper and embedded methods. Filter method applied before model building. As our problem was classification type, there were two assumptions were there which need to be satisfied. The first one is linearity and second one is no multicollinearity. Our output variable was categorical. So, checking linearity in between one continuous column and categorical output column, we use Kendall's and ANOVA test. And for checking linearity in between categorical and categorical output, we used chi-square test and mutual information. To checking the number of no multicollinearity, we use VIF which is variance inflation factor. And from the pre-based algorithm, we got the future importance which is embedded method that how we received our most important 25 features on which we build our final model. The next step was model building. As our problem was binary classification type, we use different algorithms such as logistic regression, KNN classifier, decision tree and random forest. We build a model using this algorithm, set the threshold for getting and tuning the value of Fn and Fp in the logistic regression. Did hyperparameter tuning and KNN classifier by tune for tuning the value of k and tuning the methods using for calculating the distance such as Euclidean and Manhattan. In decision tree and the random forest algorithm, we tune the values such as criteria, max depth, minimum sample split, minimum sample leaf and estimator, max features and OBB score and the bootstrap. Then we went for model evaluation. We calculate metrics such as accuracy, confusion metrics and classification report. The accuracy score was not alone was there to justify the the accuracy of that particular model or the performance of that particular model. So, we use confusion metrics which shows the performance of the model. Minimum value of Fp and Fn represents the model working good. The classification report gives value of precision, recall and F1 score which metrics is most important was depend on the problem statement. In our case, our target was minimizing the risk and optimizing the profit. So, recall and precision both were important. So, metric F1 score which is harmonic mean of precision and recall. We selected the metric F1 score which was which is harmonic mean of precision and recall. After all trial and error, we get best performance by using random forest algorithm and doing hyper and after doing hyperparameter tuning. We create the pickle and the json file. With the help of python developer, we wrote the API using flask framework and tested our API on postman. After that the deployment. In deployment, the model on client service with with the help of amazon web services, there was special team was present to do that task. There was UI UX developer, frontend developer and DevOps team. I knew the steps because I have deployed my personal project. So, this is all about my bankruptcy prediction model project.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio_file= open(\"/Users/rupalivalanju/Documents/Practice/summary/demo.mp3\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful statement, without trust communication breaks, here's why, in any human interaction the required amount of communication is inversely proportional to the level of trust, which means if there's very little trust, you require talking a lot, more attention, more listen call me at that party, okay, but if there's a lot of trust, then you require less communication, you require less listen I need to see you very often.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "audio_file= open(\"/Users/rupalivalanju/Documents/Practice/summary/video.mp4\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "converted_text = transcript[\"text\"]\n",
    "print(converted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is a discipline that focuses on designing and optimizing language model prompts for different applications and research topics, helping to better understand the capabilities and limitations of large language models. This guide provides all the latest resources related to prompt engineering, including papers, models, and tools, in order to help develop and interface with these language models, as well as improve their safety and build new capabilities.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import openai\n",
    "\n",
    "# openai.api_key = os.getenv(\"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\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"You are a language model AI developed by OpenAI. Please read the following article and provide a concise summary:\\n\\nArticle:\\nPrompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs).\\nResearchers use prompt engineering to improve the capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning. Developers use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other tools.\\nPrompt engineering is not just about designing and developing prompts. It encompasses a wide range of skills and techniques that are useful for interacting and developing with LLMs. It's an important skill to interface, build with, and understand capabilities of LLMs. You can use prompt engineering to improve safety of LLMs and build new capabilities like augmenting LLMs with domain knowledge and external tools.\\nMotivated by the high interest in developing with LLMs, we have created this new prompt engineering guide that contains all the latest papers, learning guides, models, lectures, references, new LLM capabilities, and tools related to prompt engineering.\\n\\nSummary:\\n\",\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "generated_text = response[\"choices\"][0][\"text\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This means that trust replaces communication because if communication decreases, trust increases and if communication increases, trust decreases.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=f\"You are a language model AI developed by OpenAI. Please read the following article and provide a concise summary:\\n\\n{converted_text}\",\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "generated_text = response[\"choices\"][0][\"text\"]\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
